{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>\n",
    "\n",
    "This notebook demonstrates the use of Amazon SageMaker and SKLearn to pre-process a purpose-built wind turbine dataset to simulate a predictive maintenance use-case.\n",
    "\n",
    "The implementation is provided for educational purposes only and does not take into account certain optimizations, with the aim to keep it simple and make it very easy to follow during a lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing some libraries and choosing the AWS Region and AWS Role we will use.\n",
    "Also, we need to change the bucket_name to the bucket containing the wind turbine training data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-west-1\n",
      "arn:aws:iam::825935527263:role/gianpo-path/SageMaker-Notebook-Role\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(region)\n",
    "print(role)\n",
    "\n",
    "bucket_name = 'gianpo-predictive-maintenance'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Exploration</h2>\n",
    "\n",
    "We first download the dataset from the S3 bucket to the notebook instance. After running the cell below, you can optionally check that the file was downloaded to the notebook instance throught the Jupyter notebook file browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "s3.Bucket(bucket_name).download_file('data/windturbine_raw_data.csv', 'windturbine_raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>turbine_type</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>RPM_blade</th>\n",
       "      <th>oil_temperature</th>\n",
       "      <th>oil_level</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>vibrations_frequency</th>\n",
       "      <th>pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>breakdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TID003</td>\n",
       "      <td>HAWT</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>E</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TID010</td>\n",
       "      <td>HAWT</td>\n",
       "      <td>85</td>\n",
       "      <td>78</td>\n",
       "      <td>36.0</td>\n",
       "      <td>28</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>62</td>\n",
       "      <td>NE</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TID007</td>\n",
       "      <td>HAWT</td>\n",
       "      <td>47</td>\n",
       "      <td>31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>23</td>\n",
       "      <td>46</td>\n",
       "      <td>62</td>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>N</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TID008</td>\n",
       "      <td>VAWT</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>38.0</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>66</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>SW</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TID003</td>\n",
       "      <td>HAWT</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>46.0</td>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>W</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TID001</td>\n",
       "      <td>HAWT</td>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>SW</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TID009</td>\n",
       "      <td>HAWT</td>\n",
       "      <td>80</td>\n",
       "      <td>25</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>NW</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TID002</td>\n",
       "      <td>VAWT</td>\n",
       "      <td>59</td>\n",
       "      <td>29</td>\n",
       "      <td>37.0</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>83</td>\n",
       "      <td>13</td>\n",
       "      <td>55</td>\n",
       "      <td>SE</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TID009</td>\n",
       "      <td>HAWT</td>\n",
       "      <td>58</td>\n",
       "      <td>16</td>\n",
       "      <td>48.0</td>\n",
       "      <td>10</td>\n",
       "      <td>43</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>NE</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TID001</td>\n",
       "      <td>HAWT</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>75</td>\n",
       "      <td>S</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  turbine_id turbine_type  wind_speed  RPM_blade  oil_temperature  oil_level  \\\n",
       "0     TID003         HAWT          80         61              NaN         34   \n",
       "1     TID010         HAWT          85         78             36.0         28   \n",
       "2     TID007         HAWT          47         31             31.0         23   \n",
       "3     TID008         VAWT          73         70             38.0          8   \n",
       "4     TID003         HAWT          16         23             46.0          9   \n",
       "5     TID001         HAWT          78         71             30.0         11   \n",
       "6     TID009         HAWT          80         25             37.0         31   \n",
       "7     TID002         VAWT          59         29             37.0         10   \n",
       "8     TID009         HAWT          58         16             48.0         10   \n",
       "9     TID001         HAWT          23         38             31.0         28   \n",
       "\n",
       "   temperature  humidity  vibrations_frequency  pressure wind_direction  \\\n",
       "0           33        26                     1        77              E   \n",
       "1           35        43                    15        62             NE   \n",
       "2           46        62                    15        32              N   \n",
       "3           17        66                     6        80             SW   \n",
       "4           76        53                    14        29              W   \n",
       "5           66        79                     1        81             SW   \n",
       "6           40        75                     4        56             NW   \n",
       "7           25        83                    13        55             SE   \n",
       "8           43        17                     4        44             NE   \n",
       "9           26        32                    11        75              S   \n",
       "\n",
       "  breakdown  \n",
       "0        no  \n",
       "1       yes  \n",
       "2        no  \n",
       "3       yes  \n",
       "4        no  \n",
       "5        no  \n",
       "6        no  \n",
       "7        no  \n",
       "8        no  \n",
       "9        no  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "\n",
    "df = pandas.read_csv('windturbine_raw_data.csv', header=None)\n",
    "df.columns = ['turbine_id', 'turbine_type', 'wind_speed', 'RPM_blade', 'oil_temperature', 'oil_level', 'temperature', \n",
    "              'humidity', 'vibrations_frequency', 'pressure', 'wind_direction', 'breakdown']\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "turbine_id               object\n",
       "turbine_type             object\n",
       "wind_speed                int64\n",
       "RPM_blade                 int64\n",
       "oil_temperature         float64\n",
       "oil_level                 int64\n",
       "temperature               int64\n",
       "humidity                  int64\n",
       "vibrations_frequency      int64\n",
       "pressure                  int64\n",
       "wind_direction           object\n",
       "breakdown                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display some descriptive statistics for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>RPM_blade</th>\n",
       "      <th>oil_temperature</th>\n",
       "      <th>oil_level</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>vibrations_frequency</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>961703.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.990414</td>\n",
       "      <td>50.010095</td>\n",
       "      <td>37.435021</td>\n",
       "      <td>19.998577</td>\n",
       "      <td>50.023570</td>\n",
       "      <td>50.014965</td>\n",
       "      <td>7.994064</td>\n",
       "      <td>49.985960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.486019</td>\n",
       "      <td>20.498963</td>\n",
       "      <td>7.640262</td>\n",
       "      <td>8.944855</td>\n",
       "      <td>20.496239</td>\n",
       "      <td>20.483369</td>\n",
       "      <td>4.319314</td>\n",
       "      <td>20.501076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           wind_speed       RPM_blade  oil_temperature       oil_level  \\\n",
       "count  1000000.000000  1000000.000000    961703.000000  1000000.000000   \n",
       "mean        49.990414       50.010095        37.435021       19.998577   \n",
       "std         20.486019       20.498963         7.640262        8.944855   \n",
       "min         15.000000       15.000000        25.000000        5.000000   \n",
       "25%         32.000000       32.000000        31.000000       12.000000   \n",
       "50%         50.000000       50.000000        37.000000       20.000000   \n",
       "75%         68.000000       68.000000        44.000000       28.000000   \n",
       "max         85.000000       85.000000        50.000000       35.000000   \n",
       "\n",
       "          temperature        humidity  vibrations_frequency        pressure  \n",
       "count  1000000.000000  1000000.000000        1000000.000000  1000000.000000  \n",
       "mean        50.023570       50.014965              7.994064       49.985960  \n",
       "std         20.496239       20.483369              4.319314       20.501076  \n",
       "min         15.000000       15.000000              1.000000       15.000000  \n",
       "25%         32.000000       32.000000              4.000000       32.000000  \n",
       "50%         50.000000       50.000000              8.000000       50.000000  \n",
       "75%         68.000000       68.000000             12.000000       68.000000  \n",
       "max         85.000000       85.000000             15.000000       85.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive examples: 136579\n",
      "Number of negative examples: 863421\n"
     ]
    }
   ],
   "source": [
    "df_ok = df[df['breakdown'] == 'yes']\n",
    "print('Number of positive examples: ' + str(df_ok.shape[0]))\n",
    "\n",
    "df_nok = df[df['breakdown'] == 'no']\n",
    "print('Number of negative examples: ' + str(df_nok.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "turbine_id                   0\n",
       "turbine_type            100107\n",
       "wind_speed                   0\n",
       "RPM_blade                    0\n",
       "oil_temperature          38297\n",
       "oil_level                    0\n",
       "temperature                  0\n",
       "humidity                     0\n",
       "vibrations_frequency         0\n",
       "pressure                     0\n",
       "wind_direction               0\n",
       "breakdown                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'TID006'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.where(df.turbine_type.isnull()).turbine_id.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's summarize our findings:\n",
    "<ul>\n",
    "    <li><b>turbine_id</b> is a string identifier, that we choose to preserve in the model and we need to encode.</li>\n",
    "    <li><b>turbine_type</b> is a categorical attribute, and has some missing values. More specifically, all values for turbine TID006 are missing. In this specific case we can choose to replace the value with a constant.</li>\n",
    "    <li><b>oil_temperature</b> is a numeric attribute, and has some missing values.</li>\n",
    "    <li><b>wind_direction</b> is a categorical string attribute, that we need to encode.</li>\n",
    "    <li><b>breakdown</b> is our target variable, that we need to encode.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do preprocessing of our data. We will use the Amazon SageMaker built-in SKLearn container to do this, with a script as an entry point. The script is very similar to a script you might run outside of SageMaker, but you can access useful properties about the SageMaker environment through various environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StringIO\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshutil\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.compose\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m ColumnTransformer\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.externals\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m joblib\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.impute\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SimpleImputer\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.pipeline\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Pipeline\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.preprocessing\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StandardScaler, OneHotEncoder\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_containers.beta.framework\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\r\n",
      "    content_types, encoders, env, modules, transformer, worker)\r\n",
      "\r\n",
      "feature_columns_names = [\u001b[33m'\u001b[39;49;00m\u001b[33mturbine_id\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mturbine_type\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwind_speed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRPM_blade\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33moil_temperature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33moil_level\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtemperature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mhumidity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mvibrations_frequency\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpressure\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwind_direction\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "\r\n",
      "label_column = \u001b[33m'\u001b[39;49;00m\u001b[33mbreakdown\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--prep\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_PREP\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    args = parser.parse_args()\r\n",
      "    raw_data = pd.read_csv(args.prep + \u001b[33m'\u001b[39;49;00m\u001b[33m/windturbine_raw_data.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    raw_data.columns = feature_columns_names + [label_column]\r\n",
      "    \r\n",
      "    numeric_features = [\u001b[33m'\u001b[39;49;00m\u001b[33mwind_speed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mRPM_blade\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33moil_temperature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33moil_level\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtemperature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mhumidity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mvibrations_frequency\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpressure\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    numeric_transformer = Pipeline(steps=[\r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mimputer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, SimpleImputer(strategy=\u001b[33m'\u001b[39;49;00m\u001b[33mmedian\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)),\r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mscaler\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StandardScaler())])\r\n",
      "    \r\n",
      "    categorical_features = [\u001b[33m'\u001b[39;49;00m\u001b[33mturbine_id\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwind_direction\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    categorical_transformer = Pipeline(steps=[\r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mimputer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, SimpleImputer(strategy=\u001b[33m'\u001b[39;49;00m\u001b[33mconstant\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, fill_value=\u001b[33m'\u001b[39;49;00m\u001b[33mmissing\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)),\r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33monehot\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, OneHotEncoder(handle_unknown=\u001b[33m'\u001b[39;49;00m\u001b[33mignore\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))])\r\n",
      "    \r\n",
      "    turbine_type_feature = [\u001b[33m'\u001b[39;49;00m\u001b[33mturbine_type\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    turbine_type_transformer = Pipeline(steps=[\r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mimputer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, SimpleImputer(strategy=\u001b[33m'\u001b[39;49;00m\u001b[33mconstant\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, fill_value=\u001b[33m'\u001b[39;49;00m\u001b[33mHAWT\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)),\r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33monehot\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, OneHotEncoder(handle_unknown=\u001b[33m'\u001b[39;49;00m\u001b[33mignore\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))])\r\n",
      "    \r\n",
      "    preprocessor = ColumnTransformer(\r\n",
      "        transformers=[\r\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mnum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, numeric_transformer, numeric_features),\r\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mcat\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, categorical_transformer, categorical_features),\r\n",
      "            (\u001b[33m'\u001b[39;49;00m\u001b[33mttype\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, turbine_type_transformer, turbine_type_feature)],\r\n",
      "        remainder=\u001b[33m\"\u001b[39;49;00m\u001b[33mdrop\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "                                       \r\n",
      "    preprocessor.fit(raw_data)\r\n",
      "\r\n",
      "    joblib.dump(preprocessor, os.path.join(args.model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(input_data, content_type):\r\n",
      "    \u001b[33m\"\"\"Parse input data payload\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    We currently only take csv input. Since we need to process both labelled\u001b[39;49;00m\r\n",
      "\u001b[33m    and unlabelled data we first determine whether the label column is present\u001b[39;49;00m\r\n",
      "\u001b[33m    by looking at how many columns were provided.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "        \u001b[37m# Read the raw input data as CSV.\u001b[39;49;00m\r\n",
      "        df = pd.read_csv(StringIO(input_data), \r\n",
      "                         header=\u001b[36mNone\u001b[39;49;00m)\r\n",
      "\r\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(df.columns) == \u001b[36mlen\u001b[39;49;00m(feature_columns_names) + \u001b[34m1\u001b[39;49;00m:\r\n",
      "            \u001b[37m# This is a labelled example, includes the ring label\u001b[39;49;00m\r\n",
      "            df.columns = feature_columns_names + [label_column]\r\n",
      "        \u001b[34melif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(df.columns) == \u001b[36mlen\u001b[39;49;00m(feature_columns_names):\r\n",
      "            \u001b[37m# This is an unlabelled example.\u001b[39;49;00m\r\n",
      "            df.columns = feature_columns_names\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m df\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m{} not supported by script!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(content_type))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction, accept):\r\n",
      "    \u001b[33m\"\"\"Format prediction output\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    The default accept/content-type between containers for serial inference is JSON.\u001b[39;49;00m\r\n",
      "\u001b[33m    We also want to set the ContentType or mimetype as the same value as accept so the next\u001b[39;49;00m\r\n",
      "\u001b[33m    container can read the response payload correctly.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m accept == \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "        instances = []\r\n",
      "        \u001b[34mfor\u001b[39;49;00m row \u001b[35min\u001b[39;49;00m prediction.tolist():\r\n",
      "            instances.append({\u001b[33m\"\u001b[39;49;00m\u001b[33mfeatures\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: row})\r\n",
      "\r\n",
      "        json_output = {\u001b[33m\"\u001b[39;49;00m\u001b[33minstances\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: instances}\r\n",
      "\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m worker.Response(json.dumps(json_output), accept, mimetype=accept)\r\n",
      "    \u001b[34melif\u001b[39;49;00m accept == \u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m worker.Response(encoders.encode(prediction, accept), accept, mimetype=accept)\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m RuntimeException(\u001b[33m\"\u001b[39;49;00m\u001b[33m{} accept type is not supported by this script.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(accept))\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\r\n",
      "    \u001b[33m\"\"\"Preprocess input data\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    We implement this because the default predict_fn uses .predict(), but our model is a preprocessor\u001b[39;49;00m\r\n",
      "\u001b[33m    so we want to use .transform().\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m    The output is returned in the following order:\u001b[39;49;00m\r\n",
      "\u001b[33m\u001b[39;49;00m\r\n",
      "\u001b[33m        rest of features either one hot encoded or standardized\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    features = model.transform(input_data)\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m label_column \u001b[35min\u001b[39;49;00m input_data:\r\n",
      "        input_data[label_column] = np.where(input_data[label_column]==\u001b[33m'\u001b[39;49;00m\u001b[33myes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[34m1\u001b[39;49;00m, \u001b[34m0\u001b[39;49;00m)\r\n",
      "        \u001b[37m# Return the label (as the first column) and the set of features.\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m np.insert(features, \u001b[34m0\u001b[39;49;00m, input_data[label_column], axis=\u001b[34m1\u001b[39;49;00m)\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        \u001b[37m# Return only the set of features\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m features\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\r\n",
      "    \u001b[33m\"\"\"Deserialize fitted model\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    preprocessor = joblib.load(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mmodel.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m preprocessor\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize '1-predmain-expprep-sklearn-script.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: predmain-expprep-sklearn-2019-05-02-18-50-10-249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-02 18:50:10 Starting - Starting the training job...\n",
      "2019-05-02 18:50:12 Starting - Launching requested ML instances......\n",
      "2019-05-02 18:51:12 Starting - Preparing the instances for training......\n",
      "2019-05-02 18:52:36 Downloading - Downloading input data\n",
      "2019-05-02 18:52:36 Training - Training image download completed. Training in progress.\n",
      "2019-05-02 18:52:36 Uploading - Uploading generated training model\n",
      "\u001b[31m2019-05-02 18:52:26,697 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:26,700 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:26,711 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:26,944 sagemaker-containers INFO     Module predmain-expprep-sklearn-script does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:26,944 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:26,944 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:26,944 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: predmain-expprep-sklearn-script\n",
      "  Running setup.py bdist_wheel for predmain-expprep-sklearn-script: started\n",
      "  Running setup.py bdist_wheel for predmain-expprep-sklearn-script: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-4g4v83_b/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built predmain-expprep-sklearn-script\u001b[0m\n",
      "\u001b[31mInstalling collected packages: predmain-expprep-sklearn-script\u001b[0m\n",
      "\u001b[31mSuccessfully installed predmain-expprep-sklearn-script-1.0.0\u001b[0m\n",
      "\u001b[31mYou are using pip version 18.1, however version 19.1 is available.\u001b[0m\n",
      "\u001b[31mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:28,027 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:28,037 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"num_cpus\": 8,\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"log_level\": 20,\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"channel_input_dirs\": {\n",
      "        \"prep\": \"/opt/ml/input/data/prep\"\n",
      "    },\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"module_dir\": \"s3://gianpo-predictive-maintenance/code/predmain-expprep-sklearn-2019-05-02-18-50-10-249/source/sourcedir.tar.gz\",\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"user_entry_point\": \"predmain-expprep-sklearn-script.py\",\n",
      "    \"job_name\": \"predmain-expprep-sklearn-2019-05-02-18-50-10-249\",\n",
      "    \"module_name\": \"predmain-expprep-sklearn-script\",\n",
      "    \"input_data_config\": {\n",
      "        \"prep\": {\n",
      "            \"RecordWrapperType\": \"None\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"ContentType\": \"text/csv\"\n",
      "        }\n",
      "    },\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"hyperparameters\": {},\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"num_gpus\": 0,\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"resource_config\": {\n",
      "        \"network_interface_name\": \"ethwe\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"current_host\": \"algo-1\"\n",
      "    }\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python35.zip:/usr/lib/python3.5:/usr/lib/python3.5/plat-x86_64-linux-gnu:/usr/lib/python3.5/lib-dynload:/usr/local/lib/python3.5/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=predmain-expprep-sklearn-script.py\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"prep\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=predmain-expprep-sklearn-script\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"prep\":\"/opt/ml/input/data/prep\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"prep\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"predmain-expprep-sklearn-2019-05-02-18-50-10-249\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://gianpo-predictive-maintenance/code/predmain-expprep-sklearn-2019-05-02-18-50-10-249/source/sourcedir.tar.gz\",\"module_name\":\"predmain-expprep-sklearn-script\",\"network_interface_name\":\"ethwe\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"predmain-expprep-sklearn-script.py\"}\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://gianpo-predictive-maintenance/code/predmain-expprep-sklearn-2019-05-02-18-50-10-249/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"prep\"]\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_PREP=/opt/ml/input/data/prep\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[31mSM_HPS={}\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python3 -m predmain-expprep-sklearn-script\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m2019-05-02 18:52:32,578 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2019-05-02 18:52:42 Completed - Training job completed\n",
      "Billable seconds: 29\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "entry_point = 'predmain-expprep-sklearn-script.py'\n",
    "output_location = 's3://{0}/output'.format(bucket_name)\n",
    "code_location = 's3://{0}/code'.format(bucket_name)\n",
    "\n",
    "sklearn_preprocessor = SKLearn(\n",
    "    entry_point=entry_point,\n",
    "    role=role,\n",
    "    output_path=output_location,\n",
    "    code_location=code_location,\n",
    "    base_job_name='predmain-expprep-sklearn',\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=\"ml.c5.2xlarge\")\n",
    "\n",
    "preprocessing_input = sagemaker.session.s3_input('s3://{0}/data/windturbine_raw_data.csv'.format(bucket_name), content_type='text/csv')\n",
    "\n",
    "sklearn_preprocessor.fit({'prep': preprocessing_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Batch Transform</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once our model has been fit, we can use Amazon SageMaker Batch Transform to transform our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: predmain-expprep-sklearn-2019-05-02-18-50-10-249\n",
      "INFO:sagemaker:Creating transform job with name: predmain-expprep-sklearn-2019-05-02-18-53-37-756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for transform job: predmain-expprep-sklearn-2019-05-02-18-53-37-756\n",
      ".....................................!\n"
     ]
    }
   ],
   "source": [
    "output_location = 's3://{0}/data'.format(bucket_name)\n",
    "\n",
    "transformer = sklearn_preprocessor.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.c5.4xlarge',\n",
    "    output_path=output_location,\n",
    "    assemble_with = 'Line',\n",
    "    accept='text/csv')\n",
    "\n",
    "transformer.transform('s3://{0}/data/'.format(bucket_name), content_type='text/csv', split_type='Line')\n",
    "print('Waiting for transform job: ' + transformer.latest_transform_job.job_name)\n",
    "transformer.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
